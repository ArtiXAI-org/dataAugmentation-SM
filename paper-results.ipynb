{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c295fbb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b73739",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "presentation of the data\n",
    "I would say 100 dataset of various size but of high interest, maybe the best with my method and of high interest\n",
    "ADMET + bioactivity\n",
    "\n",
    "\n",
    "chemical space\n",
    "BEFORE / AFTER\n",
    "experimental value\n",
    "\n",
    "cumulative distribution\n",
    "r2 BEFORE/AFTER\n",
    "size BEFORE/AFTER\n",
    "\n",
    "scatter plot\n",
    "R2 improvement vs size of original data\n",
    "size after vs size BEFORE\n",
    "R2 after VS R2 before \n",
    "\n",
    "boxplot\n",
    "R2 on test of before after with statistical diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b328fa52",
   "metadata": {},
   "source": [
    "Title: Enhancing ADMET and Bioactivity Prediction through Matched Molecular Pair Augmentation\n",
    "\n",
    "Abstract:\n",
    "Sparse experimental data remains a bottleneck in the application of machine learning (ML) to predict ADMET properties and bioactivity of small molecules. We present a data augmentation method using matched molecular pairs (MMPs) to synthetically expand experimental datasets. We apply this strategy to 100 curated datasets of pharmacological relevance and demonstrate consistent improvements in predictive performance using Random Forest (RF), XGBoost, and Graph Neural Networks (GNNs). We conduct extensive statistical analyses and visualize the chemical and predictive spaces before and after augmentation. Our findings suggest MMP-based augmentation significantly enhances model generalization in low-data regimes.\n",
    "\n",
    "1. Introduction\n",
    "\n",
    "Problem statement: Experimental ADMET and bioactivity data are limited and unevenly distributed, particularly in early-stage drug discovery. This scarcity constrains the applicability of ML models.\n",
    "\n",
    "Motivation: In pharmaceutical pipelines, reliable prediction in low-data regimes is critical, especially for off-target liabilities, metabolic stability, or specific bioactivities with few known ligands.\n",
    "\n",
    "Previous work: Outline MMP concept from Hussain and Rea (2002), and recent applications (e.g., Kramer et al., Roche). Explain how prior work focused on interpretation or transformation rules but not large-scale data expansion.\n",
    "\n",
    "Contribution: We propose and validate a framework for augmenting datasets using MMPs and demonstrate its effect on ML performance across multiple endpoints.\n",
    "\n",
    "2. Related Work\n",
    "\n",
    "ADMET modeling: Classical QSAR, ML (RF, XGB), DL (GNN, ChemBERTa, etc.).\n",
    "\n",
    "Data augmentation in chemoinformatics: SMILES-based techniques, domain adversarial approaches.\n",
    "\n",
    "MMP in drug design: Interpretation, SAR analysis, compound optimization. Few have evaluated its value for pure predictive modeling.\n",
    "\n",
    "3. Methods\n",
    "\n",
    "Datasets:\n",
    "\n",
    "Source: Public ADMET/Bioactivity sets (ChEMBL, Tox21, PubChem).\n",
    "\n",
    "Selection: ~100 datasets, varied in size, endpoints, and value.\n",
    "\n",
    "Preprocessing: Standardization, deduplication, canonicalization.\n",
    "\n",
    "Augmentation Strategy:\n",
    "\n",
    "MMPs extracted via fragmentation rules.\n",
    "\n",
    "Augmented pairs generated using experimental anchors and applied transformations.\n",
    "\n",
    "Filtering: Keep pairs with known experimental data for at least one anchor.\n",
    "\n",
    "Annotate augmented entries with predicted/estimated values, standard deviations.\n",
    "\n",
    "Model Architectures:\n",
    "\n",
    "RF, XGB: Descriptor-based (ECFP4).\n",
    "\n",
    "GNN: Message-passing model (e.g., GCN, D-MPNN), trained on molecular graphs.\n",
    "\n",
    "MTL vs STL: Compare single-task vs multi-task learning performance with and without augmentation.\n",
    "\n",
    "Common training pipeline, same seeds.\n",
    "\n",
    "Validation:\n",
    "\n",
    "5-fold CV repeated 3 times.\n",
    "\n",
    "Train on original vs augmented sets.\n",
    "\n",
    "Hold-out test set contains only experimental compounds.\n",
    "\n",
    "Statistical Testing:\n",
    "\n",
    "Paired t-test and Wilcoxon signed-rank test for R^2 and RMSE.\n",
    "\n",
    "Additional Evaluations:\n",
    "\n",
    "Domain classification: Train classifier to distinguish experimental vs augmented (ROC, confusion matrix).\n",
    "\n",
    "Applicability Domain (AD): Train Isolation Forests on original vs augmented sets, compare fraction of test compounds within AD.\n",
    "\n",
    "Saturation analysis: Train models with 10%, 25%, 50%, 75%, 100% of augmented data.\n",
    "\n",
    "Standard deviation landscape: UMAP colored by std of consensus model (before/after).\n",
    "\n",
    "MMP class-level activity: Track number of augmented compounds per transformation class to identify most productive transformation types.\n",
    "\n",
    "Cross-architecture benchmark: STL-no-aug, STL-aug, MTL-no-aug, MTL-aug to identify synergy between multitask learning and augmentation.\n",
    "\n",
    "Database-scale training: Train one MTL model on all datasets (original and augmented) to evaluate generalization potential on large-scale chemical space.\n",
    "\n",
    "4. Results and Figures\n",
    "\n",
    "4.1 Descriptive Characterization (Figure 1):\n",
    "\n",
    "Goal: Show augmentation impact on data size and chemical diversity.\n",
    "\n",
    "Panel A: Hexbin plot of dataset size before vs after (log-scale).\n",
    "\n",
    "Panel B: Cumulative distribution of dataset sizes.\n",
    "\n",
    "Panel C: Cumulative distribution of R^2 before and after.\n",
    "\n",
    "Panel D: UMAP of chemical space (Before/After), color by: (i) data source (exp vs augmented), (ii) std of augmented value, (iii) experimental Y.\n",
    "\n",
    "4.2 Performance Comparison (Figure 2):\n",
    "\n",
    "Goal: Quantify performance gains.\n",
    "\n",
    "Panel A: Boxplot of test set R^2 (original vs augmented) across all datasets.\n",
    "\n",
    "Panel B: Scatter: R^2 before vs after (1:1 reference line).\n",
    "\n",
    "Panel C: Scatter: R^2 improvement vs original dataset size.\n",
    "\n",
    "Panel D: Scatter: Augmented size vs R^2 gain.\n",
    "\n",
    "4.3 Learning Dynamics & Saturation (Figure 3):\n",
    "\n",
    "Goal: Show how model learns differently with more data, identify plateau.\n",
    "\n",
    "Panel A: Learning curves (train size vs R^2).\n",
    "\n",
    "Panel B: Same for RMSE.\n",
    "\n",
    "4.4 Applicability Domain (Figure 4):\n",
    "\n",
    "Goal: Evaluate domain coverage improvement.\n",
    "\n",
    "Panel A: Barplot of % test compounds in AD (before vs after) using Isolation Forest.\n",
    "\n",
    "Panel B: AD score distribution (boxplot).\n",
    "\n",
    "4.5 Error Space Visualization (Figure 5):\n",
    "\n",
    "Goal: Show reduction in prediction error across chemical space.\n",
    "\n",
    "Panel A: UMAP colored by median absolute error (MAE) on test set (before vs after).\n",
    "\n",
    "Panel B: Density overlay to highlight coverage improvement in active space.\n",
    "\n",
    "4.6 Domain Discrimination (Figure 6):\n",
    "\n",
    "Goal: Verify realism of augmented data.\n",
    "\n",
    "Panel A: ROC curve of domain classifier.\n",
    "\n",
    "Panel B: Confusion matrix.\n",
    "\n",
    "4.7 Endpoint-Specific Effects (Figure 7):\n",
    "\n",
    "Goal: Explore which endpoint classes benefit most.\n",
    "\n",
    "Panel A: Boxplot of R^2 improvement grouped by endpoint category (e.g., toxicity, absorption).\n",
    "\n",
    "4.8 Augmentation Class Productivity (Figure 8):\n",
    "\n",
    "Goal: Identify which MMP transformation types produce the most usable data.\n",
    "\n",
    "Panel A: Barplot: number of compounds generated per transformation class.\n",
    "\n",
    "Panel B: Density of std/error for top N transformation types.\n",
    "\n",
    "4.9 Multi-task Learning Synergy (Figure 9):\n",
    "\n",
    "Goal: Compare STL and MTL with and without augmentation.\n",
    "\n",
    "Panel A: R^2 per dataset under each setup.\n",
    "\n",
    "Panel B: Delta R^2 per method.\n",
    "\n",
    "4.10 Global Model Utility (Figure 10):\n",
    "\n",
    "Goal: Evaluate a single large MTL model trained on full original+augmented set.\n",
    "\n",
    "Panel A: Test performance per task.\n",
    "\n",
    "Panel B: Error distribution vs dataset size.\n",
    "\n",
    "5. Discussion\n",
    "\n",
    "Effectiveness of augmentation: Most datasets benefit, especially small-to-medium sets.\n",
    "\n",
    "Dataset-specific insights: Some endpoints are harder to augment reliably (e.g., complex toxicities).\n",
    "\n",
    "Chemical novelty: Augmented compounds fill sparse areas of chemical space.\n",
    "\n",
    "Potential biases: Label propagation from anchor to analog may inject noise. Discuss mitigation strategies (e.g., uncertainty thresholding).\n",
    "\n",
    "AD shift: Augmentation increases model coverage and tolerance in applicability space.\n",
    "\n",
    "Saturation point: Discuss diminishing returns and ideal augmentation volume.\n",
    "\n",
    "Consensus model uncertainty: Show reduction in predictive variance in key chemical subspaces.\n",
    "\n",
    "Transformation classes: Certain MMP rules drive most useful augmentations â€” potential for rule prioritization.\n",
    "\n",
    "MTL augmentation synergy: When combined, multitask learning and augmentation outperform all other setups.\n",
    "\n",
    "Database-scale training: A single MTL model trained on full data can provide state-of-the-art baseline for many endpoints.\n",
    "\n",
    "6. Conclusion\n",
    "\n",
    "MMP-based augmentation is a simple yet powerful tool for improving ML on ADMET/bioactivity tasks.\n",
    "\n",
    "Useful in low-data regimes, early-stage pipelines.\n",
    "\n",
    "Encourages exploration of semi-synthetic data strategies in predictive modeling.\n",
    "\n",
    "Supplementary Information\n",
    "\n",
    "Full per-dataset metrics (R^2, RMSE, MAE).\n",
    "\n",
    "Details on MMP rules and filtering.\n",
    "\n",
    "Scripts, environment configs, model parameters.\n",
    "\n",
    "Examples of successful MMP transformations.\n",
    "\n",
    "Results of sensitivity analysis by augmentation %.\n",
    "\n",
    "Domain classification models and raw prediction tables.\n",
    "\n",
    "MTL training setup and full results tables.\n",
    "\n",
    "Ranked list of productive transformation types with compound counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f98c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ddc174",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be5f0b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2861ecef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b6a65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6feea5f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058a0a8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "225f5eef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85982d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e68b75c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecd0df4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef1b1c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88576575",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad8277d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a785747",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c816fedd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85651939",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b98129e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bca22b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "843aa2fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5067d58",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
