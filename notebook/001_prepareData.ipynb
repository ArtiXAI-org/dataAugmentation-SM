{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e629a7",
   "metadata": {},
   "source": [
    "# 0) Modules & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afdd842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import inchi\n",
    "\n",
    "\n",
    "# Compute InChIKey from SMILES\n",
    "def smiles_to_inchikey(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        return inchi.MolToInchiKey(mol)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def subscript(text):\n",
    "    return f\"$_{{{text}}}$\"\n",
    "\n",
    "def _replace_subscript(name):\n",
    "    name = name.replace('Caco-2-2', 'Caco-2')\n",
    "    name = name.replace('(Rat)', '(RAT)')\n",
    "    name = name.replace('(Human,', '(HUMAN,')\n",
    "    name = name.replace('(Rat,', '(RAT,')\n",
    "    name = name.replace('(po, Rat,', '(po, RAT,')\n",
    "    name = name.replace('(Mouse,', '(MOUSE,')\n",
    "    name = name.replace('(Mouse)', '(MOUSE)')\n",
    "    name = name.replace('(Rat)', '(RAT)')\n",
    "    name = name.replace('(Dog,', '(DOG,')\n",
    "    name = name.replace('Prolif (Cell)', 'Cell-prolif')\n",
    "    name = name.replace('Half Life Microsome', 'logHalf-life$_{microsomal}$')\n",
    "    name = name.replace('Half Life Plasma', 'logHalf-life$_{plasma}$')\n",
    "    name = name.replace('Clearance Microsomal', 'logClearance$_{microsomal}$')\n",
    "    name = name.replace('Clearance Total', 'logClearance$_{total}$')\n",
    "    name = name.replace('Clearance Total', 'logClearance$_{total}$')\n",
    "    name = name.replace('Clearance Renal', 'logClearance$_{renal}$')\n",
    "    name = name.replace(', Cell)', ')')\n",
    "    name = name.replace('Growth Tumor', 'Tumor-growth')\n",
    "    name = name.replace('logClearance$_{total}$ iv (RAT,', 'logClearance$_{total}$ (iv, RAT,')\n",
    "    name = name.replace('Stability Microsomal', 'Stability$_{microsomal}$')\n",
    "    name = name.replace('pVD', 'logVD')\n",
    "    return name\n",
    "\n",
    "def clean_endpoint_name(name):\n",
    "    name = name.replace('.csv', '')\n",
    "\n",
    "    # Replace raw units with readable forms (keep lowercase)\n",
    "    name = name.replace('pmL%min%kg', 'µL·min⁻¹·kg⁻¹')\n",
    "    name = name.replace('pmg%kg', 'mg·kg⁻¹')\n",
    "    name = name.replace('pHours', 'h')\n",
    "    name = name.replace('pL%kg', 'L·kg⁻¹')\n",
    "    name = name.replace('mol%kg', 'mol·kg⁻¹')\n",
    "\n",
    "    # Remove prefixes\n",
    "    name = re.sub(r'^(PUBLIC|BindingDB)___', '', name)\n",
    "\n",
    "    # Replace separators and clean up\n",
    "    name = name.replace('-', ' ').replace('_', ' ').replace('Public', '')\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "\n",
    "    # Remove \"Biochemical\"\n",
    "    name = re.sub(r'\\bBiochemical\\b', '', name)\n",
    "\n",
    "    # Fix substrings for cell types, models\n",
    "    name = re.sub(r'\\bCaco2\\b', 'Caco-2', name)\n",
    "    name = re.sub(r'\\bCaco\\b', 'Caco-2', name)\n",
    "    name = re.sub(r'MDCK LE\\b', 'MDCK-LE', name)\n",
    "    name = re.sub(r'MDCK MDR1\\b', 'MDCK-MDR1', name)\n",
    "    name = re.sub(r'MCDK MDR1\\b', 'MDCK-MDR1', name)\n",
    "\n",
    "    # Apply LaTeX-style subscripts\n",
    "    name = re.sub(r'\\bp(IC|GI|LD|TD)50\\b', lambda m: f\"p{m.group(1)}{subscript('50')}\", name)\n",
    "    name = re.sub(r'\\bpVDss\\b', lambda _: f\"pVD{subscript('ss')}\", name)\n",
    "    name = re.sub(r'\\bpKi\\b', lambda _: f\"pK{subscript('i')}\", name)\n",
    "    name = re.sub(r'\\bpKd\\b', lambda _: f\"pK{subscript('d')}\", name)\n",
    "\n",
    "    # logX formatting with special subscripts\n",
    "    name = re.sub(r'\\bLogD74\\b', lambda _: f\"logD{subscript('7-4')}\", name)\n",
    "    name = re.sub(r'\\bLogPapp\\b', lambda _: f\"logP{subscript('app')}\", name)\n",
    "    name = re.sub(r'\\bLogPow\\b', lambda _: f\"logP{subscript('ow')}\", name)\n",
    "    name = re.sub(r'\\bLogS Water\\b', lambda _: f\"logS{subscript('water')}\", name)\n",
    "    name = re.sub(r'\\bLogS Apparent\\b', lambda _: f\"logS{subscript('buffer')}\", name)\n",
    "    name = re.sub(r'\\bLog([A-Z])', r'log\\1', name)\n",
    "\n",
    "\n",
    "    # Tokenize and collect metadata\n",
    "    tokens = name.split()\n",
    "    main = []\n",
    "    meta = []\n",
    "\n",
    "    # Reference species, sources, tissues, etc.\n",
    "    meta_whitelist = {\n",
    "        'MOUSE', 'RAT', 'HUMAN', 'DOG', 'HAMSTER', 'CELL',\n",
    "        'PO', 'CAVPO', 'TETCF', 'CANEN', 'MYCTU', 'SARS', 'SARS2',\n",
    "        'MDCK-MDR1', 'MDCK-LE', 'Caco-2', 'PAMPA', 'BOVIN', 'HV1BR', \n",
    "        'HV1H2', 'PIG', 'BACAN', 'TRYCR', 'CANAL', 'ECOLX',  'ECOLI', \n",
    "        'MESAU', 'HELPY', 'HCMVA', 'CHICK', \"HCMVA\", 'RICCO', 'MACFA', \n",
    "        'PLAF7','SPIOL', 'HV1N5', 'HV1H2', 'HV1BR', 'HV1B1', 'HCVJ4', \n",
    "        'HCVCO', 'HCVBK', 'HCV77', 'SHEEP', 'I34A1', 'CARPA','MELGA', \n",
    "        'INBLE', 'I77AB', 'I75A5', 'I34A1', 'I33A0', 'CLOPF', 'HELPJ', \n",
    "        'YEAST', 'PHOPY', 'PSEAE', 'HHV1S', \"PORG3\", 'MYCSM', 'STAAU',\n",
    "        'HBVD3','ENTFA','HV1H2','PNECA', 'TOXGO', 'PLAFK', 'LEIMA', 'STAAU',\n",
    "        'STAAM', 'TRYCR', 'STAAE', 'RABIT', 'AGABI', 'BACFG', 'BACSU', 'CLOBO', 'ELEEL', 'ENTCL', 'HORSE', 'KLEPN', 'LACCA', 'SERMA', 'STAAR'\n",
    "    }\n",
    "\n",
    "    unit_patterns = ['µL·min⁻¹·kg⁻¹', 'mg·kg⁻¹', 'L·kg⁻¹', 'mol·kg⁻¹', 'h']\n",
    "\n",
    "    for token in tokens:\n",
    "        token_upper = token.upper()\n",
    "        if token in unit_patterns or token in meta_whitelist or token_upper in meta_whitelist:\n",
    "            meta.append(token)\n",
    "        elif token_upper in meta_whitelist:\n",
    "            meta.append(token_upper)\n",
    "        elif token.isupper() and len(token) <= 6:  # likely gene or protein name\n",
    "            main.append(token)\n",
    "        else:\n",
    "            main.append(token)\n",
    "\n",
    "    # Remove duplicates from meta, preserve order\n",
    "    seen = set()\n",
    "    meta_clean = []\n",
    "    for m in meta:\n",
    "        if m not in seen:\n",
    "            seen.add(m)\n",
    "            meta_clean.append(m)\n",
    "\n",
    "\n",
    "    if meta_clean:\n",
    "        return _replace_subscript(f\"{' '.join(main)} ({', '.join(meta_clean)})\")\n",
    "    else:\n",
    "        return _replace_subscript(' '.join(main))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72984e90",
   "metadata": {},
   "source": [
    "# 1) Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89ec59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_parquet('../data/exp/oneADMET.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b8e53",
   "metadata": {},
   "source": [
    "# 2) Filter by dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b90b5eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1535/1535 [00:00<00:00, 1671.53it/s]\n",
      "100%|██████████| 1535/1535 [00:00<00:00, 3150.73it/s]\n",
      "100%|██████████| 1535/1535 [00:00<00:00, 3127.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_full is your DataFrame\n",
    "min_non_nan = 50\n",
    "max_non_nan = 10000\n",
    "\n",
    "valid_cols = [\n",
    "\n",
    "    col for col in tqdm(df_full.columns)\n",
    "    if min_non_nan <= df_full[col].notna().sum() <= max_non_nan\n",
    "]\n",
    "\n",
    "# If you want to exclude 'SMILES' and 'Set' columns from the check:\n",
    "valid_cols = [\n",
    "    col for col in tqdm(df_full.columns)\n",
    "    if col not in ['SMILES', 'Set'] and min_non_nan <= df_full[col].notna().sum() <= max_non_nan\n",
    "]\n",
    "\n",
    "to_remove = [\n",
    "    \"PUBLIC___pIC50_CYP1A2_HUMAN_Biochemical_Public.csv\",\n",
    "    \"PUBLIC___pIC50_CYP2C19_HUMAN_Biochemical_Public.csv\",\n",
    "    \"PUBLIC___pIC50_CYP2C9_HUMAN_Biochemical_Public.csv\",\n",
    "    \"PUBLIC___pIC50_CYP2D6_HUMAN_Biochemical_Public.csv\",\n",
    "    \"PUBLIC___pIC50_CYP3A4_HUMAN_Biochemical_Public.csv\",\n",
    "    \"pLD50_Unknown_Public.csv\",\n",
    "    \"PUBLIC___LogHydrationFreeEnergy_Public.csv\",\n",
    "    \"PPB_Human_Public.csv\",\n",
    "    \"BindingDB___pIC50_CYP19A_HUMAN_Biochemical.csv\",\n",
    "    \"BindingDB___pIC50_CYP1A1_HUMAN_Biochemical.csv\",\n",
    "    \"BindingDB___pIC50_CYP1A2_HUMAN_Biochemical.csv\",\n",
    "    \"BindingDB___pIC50_CYP1B1_HUMAN_Biochemical.csv\",\n",
    "    \"BindingDB___pIC50_CYP2B6_HUMAN_Biochemical.csv\",\n",
    "    \"BindingDB___pIC50_CYP4F2_HUMAN_Biochemical.csv\"\n",
    "]\n",
    "\n",
    "filtered_cols = [\n",
    "    col for col in tqdm(df_full.columns)\n",
    "    if col not in ['SMILES', 'Set']\n",
    "    and min_non_nan <= df_full[col].notna().sum() <= max_non_nan\n",
    "    and col not in to_remove\n",
    "]\n",
    "\n",
    "# Keep only SMILES, Set, and the filtered columns\n",
    "df_filtered = df_full[[\"SMILES\", \"Set\"] + filtered_cols]\n",
    "\n",
    "# Drop rows where all values in filtered_cols are NaN\n",
    "df_filtered = df_filtered.dropna(subset=filtered_cols, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72d5fb",
   "metadata": {},
   "source": [
    "# 3) Keep large enough test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ec46b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1343/1343 [00:36<00:00, 37.21it/s]\n"
     ]
    }
   ],
   "source": [
    "set_out = []\n",
    "for col in tqdm(filtered_cols):\n",
    "    # Keep only SMILES, Set, and current column\n",
    "    df_filtered = df_full[[\"SMILES\", \"Set\", col]].dropna()\n",
    "\n",
    "    # Calculate % of each set\n",
    "    set_counts = df_filtered[\"Set\"].value_counts(normalize=True)\n",
    "\n",
    "    # Print if any set has more than 10%\n",
    "    for set_name, frac in set_counts.items():\n",
    "        if frac < 0.1 and set_name == \"test\":\n",
    "            set_out.append(set_name)\n",
    "\n",
    "    # Save the filtered dataframe\n",
    "    # df_filtered.to_parquet(f'../data/exp/MTL/oneADMET_{col}.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a288fe8c",
   "metadata": {},
   "source": [
    "# 4) Filter out columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "044be3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1535/1535 [00:00<00:00, 2221.45it/s]\n"
     ]
    }
   ],
   "source": [
    "to_remove_all = to_remove + set_out\n",
    "\n",
    "filtered_cols_full = [\n",
    "    col for col in tqdm(df_full.columns)\n",
    "    if col not in ['SMILES', 'Set']\n",
    "    and min_non_nan <= df_full[col].notna().sum() <= max_non_nan\n",
    "    and col not in to_remove_all\n",
    "]\n",
    "\n",
    "# Keep only SMILES, Set, and the filtered columns\n",
    "df_filtered_MTL = df_full[[\"SMILES\", \"Set\"] + filtered_cols_full]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d57f26",
   "metadata": {},
   "source": [
    "# 5) Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f4688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1343 [00:00<?, ?it/s]/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_29177/1747748893.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered_MTL.rename(columns={old_name: new_name}, inplace=True)\n",
      "100%|██████████| 1343/1343 [00:00<00:00, 6571.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "cleaned_names = [clean_endpoint_name(name) for name in filtered_cols_full]\n",
    "endpoint_name_mapping = dict(zip(filtered_cols_full, cleaned_names))\n",
    "\n",
    "for old_name, new_name in tqdm(endpoint_name_mapping.items()):\n",
    "    # Optionally, you can rename the columns in the DataFrame\n",
    "    df_filtered_MTL.rename(columns={old_name: new_name}, inplace=True)\n",
    "\n",
    "df_filtered_MTL_cols = df_filtered_MTL.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51c1a3",
   "metadata": {},
   "source": [
    "# 6) Prepare MTL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66602e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values in filtered_cols are NaN\n",
    "try:\n",
    "    os.mkdir('../data/exp/MTL')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "df_filtered_MTL = df_filtered_MTL.dropna(subset=df_filtered_MTL_cols, how='all')\n",
    "\n",
    "df_filtered_MTL['InChIKey'] = df_filtered_MTL['SMILES'].apply(smiles_to_inchikey)\n",
    "\n",
    "# Insert InChIKey as first column\n",
    "cols = ['InChIKey'] + [col for col in df_filtered_MTL.columns if col != 'InChIKey']\n",
    "df_filtered_MTL = df_filtered_MTL[cols]\n",
    "\n",
    "df_filtered_MTL.to_parquet('../data/exp/MTL/oneADMET_LR-MTL.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113378e",
   "metadata": {},
   "source": [
    "# 7) Prepare STL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0de127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1343/1343 [00:52<00:00, 25.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare STL data\n",
    "try:\n",
    "    os.mkdir('../data/exp/STL')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "for col in tqdm(df_filtered_MTL_cols):\n",
    "    # Keep only SMILES, Set, and current column\n",
    "    df_filtered_STL = df_filtered_MTL[['InChIKey', \"SMILES\", \"Set\", col]].dropna()\n",
    "    df_filtered_STL.columns = ['InChIKey', \"SMILES\", \"SET\", \"Y\"]\n",
    "\n",
    "    # Calculate % of each set\n",
    "    set_counts = df_filtered_STL[\"SET\"].value_counts(normalize=True)\n",
    "\n",
    "    if len(df_filtered_STL.drop_duplicates(\"InChIKey\")) != len(df_filtered_STL):\n",
    "        print(f\"Duplicate InChIKey found in {col}\")\n",
    "\n",
    "    # Save the filtered dataframe\n",
    "    df_filtered_STL.to_parquet(f'../data/exp/STL/oneADMET_LR-STL---{col}.parquet', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
