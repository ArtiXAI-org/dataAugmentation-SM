{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9e629a7",
   "metadata": {},
   "source": [
    "# 0) Modules & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0de127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "import subprocess\n",
    "import hashlib\n",
    "import tempfile\n",
    "import base64\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import RDLogger\n",
    "import warnings\n",
    "import re\n",
    "from rdkit.Chem import inchi\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Disable RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"rdkit\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"rdkit\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, module=\"rdkit\")\n",
    "\n",
    "class MMPGenerator:\n",
    "    def __init__(self, df_input, output_csv, mmpa_dir='../mmpa',\n",
    "                 symmetric=True, max_heavy=14, max_ratio=0.7, verbose=True):\n",
    "        self.df_original = df_input.copy()\n",
    "        self.output_csv = output_csv\n",
    "        self.mmpa_dir = mmpa_dir\n",
    "        self.symmetric = symmetric\n",
    "        self.max_heavy = max_heavy\n",
    "        self.max_ratio = max_ratio\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def _get_inchikey(self, smiles):\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:\n",
    "            return Chem.inchi.MolToInchiKey(mol)\n",
    "        return self.encode_string(smiles)\n",
    "\n",
    "    def encode_string(self, s):\n",
    "        return base64.urlsafe_b64encode(s.encode()).decode()\n",
    "\n",
    "    def decode_string(self, b64):\n",
    "        return base64.urlsafe_b64decode(b64.encode()).decode()\n",
    "\n",
    "    def run(self):\n",
    "        self.df_original['ID'] = [self._get_inchikey(smi) for smi in self.df_original['SMILES']]\n",
    "        y_map = self.df_original.set_index('ID')['Y'].to_dict()\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as tmp:\n",
    "            smi_path = os.path.join(tmp, 'input.smi')\n",
    "            frag_path = os.path.join(tmp, 'fragmented.txt')\n",
    "            mmps_path = os.path.join(tmp, 'mmps.csv')\n",
    "            smirks_path = os.path.join(tmp, 'smirks.txt')\n",
    "            cansmirks_path = os.path.join(tmp, 'cansmirks.txt')\n",
    "\n",
    "            self.df_original[['SMILES', 'ID']].to_csv(smi_path, index=False, sep=' ', header=False)\n",
    "\n",
    "            print(\"0) Fragments generation\")\n",
    "            with open(frag_path, 'w') as out:\n",
    "                subprocess.run(['python', f'{self.mmpa_dir}/rfrag.py'], stdin=open(smi_path), stdout=out)\n",
    "\n",
    "            print(\"1) Indexing\")\n",
    "            cmd = ['python', f'{self.mmpa_dir}/indexing.py']\n",
    "            if self.symmetric:\n",
    "                cmd.append('-s')\n",
    "            if self.max_heavy:\n",
    "                cmd.extend(['-m', str(self.max_heavy)])\n",
    "            if self.max_ratio:\n",
    "                cmd.extend(['-r', str(self.max_ratio)])\n",
    "\n",
    "            with open(mmps_path, 'w') as out:\n",
    "                subprocess.run(cmd, stdin=open(frag_path), stdout=out)\n",
    "\n",
    "            with open(mmps_path) as f:\n",
    "                lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "            splits = [line.split(',') for line in lines]\n",
    "            max_len = max(len(s) for s in splits)\n",
    "\n",
    "            df = pd.DataFrame(splits, columns=['L_SMILES', 'R_SMILES', 'L_ID', 'R_ID', 'SMIRKS', 'CORE'])\n",
    "\n",
    "\n",
    "            df['L_Y'] = df['L_ID'].map(y_map)\n",
    "            df['R_Y'] = df['R_ID'].map(y_map)\n",
    "            df['Delta_Y'] = df['R_Y'] - df['L_Y']\n",
    "\n",
    "            df = df[df['SMIRKS'].apply(lambda x: isinstance(x, str) and '>>' in x)]\n",
    "\n",
    "            df['__row'] = range(len(df))\n",
    "            df[['SMIRKS', '__row']].to_csv(smirks_path, index=False, sep=' ', header=False)\n",
    "\n",
    "            print(\"2) Canonical SMIRKS generation\")\n",
    "            with open(cansmirks_path, 'w') as out:\n",
    "                subprocess.run(['python', f'{self.mmpa_dir}/cansmirk.py'], stdin=open(smirks_path), stdout=out)\n",
    "\n",
    "\n",
    "            canon_df = pd.read_csv(cansmirks_path, sep=' ', names=['Canonical_SMIRKS', 'index'])\n",
    "\n",
    "\n",
    "            df = df.merge(canon_df, left_on='__row', right_on='index').drop(columns=['__row', 'index'])\n",
    "\n",
    "            df[['L_sub', 'R_sub']] = df['Canonical_SMIRKS'].str.split('>>', expand=True)\n",
    "\n",
    "\n",
    "            df['L_sub_ID'] = [self.encode_string(k) for k in df['L_sub'].tolist()]\n",
    "            df['R_sub_ID'] = [self.encode_string(k) for k in df['R_sub'].tolist()]\n",
    "            df['SMIRKS_ID'] = [self.encode_string(k) for k in df['Canonical_SMIRKS'].tolist()]\n",
    "            df['CORE_ID'] = [self.encode_string(k) for k in df['CORE'].tolist()]\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "            df[['L_SMILES', 'R_SMILES', 'L_ID', 'R_ID', 'SMIRKS', 'CORE', 'L_Y', 'R_Y', 'Delta_Y', 'L_sub', 'R_sub', 'L_sub_ID', 'R_sub_ID', 'SMIRKS_ID', 'CORE_ID']].to_csv(\n",
    "                self.output_csv, index=False\n",
    "            )\n",
    "\n",
    "\n",
    "class MMPAugmentorFixed:\n",
    "    def __init__(self, df, min_common=4, pearson_thresh=0.3, crmsd_thresh=0.4):\n",
    "        self.df = df.copy()\n",
    "        self.min_common = min_common\n",
    "        self.pearson_thresh = pearson_thresh\n",
    "        self.crmsd_thresh = crmsd_thresh\n",
    "        self.series = {}\n",
    "        self.pair_scores = []\n",
    "        self.filtered_pairs = []\n",
    "        self.augmented_data = []\n",
    "\n",
    "    def _extract_series(self):\n",
    "        start = time.time()\n",
    "        self.series = {\n",
    "            core: group for core, group in self.df.groupby(\"CORE\")\n",
    "        }\n",
    "\n",
    "    def _compute_pairwise_scores(self):\n",
    "        start = time.time()\n",
    "        self.pair_scores = []\n",
    "        series_items = list(self.series.items())\n",
    "        total_combinations = len(series_items) * (len(series_items) - 1) // 2\n",
    "        for (core1, df1), (core2, df2) in tqdm(combinations(series_items, 2), desc=\"3) Computing pairwise correlations\", total=total_combinations):\n",
    "            subs1 = set(df1[\"L_sub\"])\n",
    "            subs2 = set(df2[\"L_sub\"])\n",
    "            common = subs1 & subs2\n",
    "            if len(common) < self.min_common:\n",
    "                continue\n",
    "\n",
    "            merged = pd.merge(\n",
    "                df1, df2,\n",
    "                left_on=[\"L_sub\", \"R_sub\"],\n",
    "                right_on=[\"L_sub\", \"R_sub\"],\n",
    "                suffixes=('_1', '_2')\n",
    "            )\n",
    "            if len(merged) < self.min_common:\n",
    "                continue\n",
    "\n",
    "            y1 = merged['Delta_Y_1'].values\n",
    "            y2 = merged['Delta_Y_2'].values\n",
    "            crmsd = np.sqrt(np.mean((y1 - y2) ** 2))\n",
    "            try:\n",
    "                corr = pearsonr(y1, y2)[0]\n",
    "            except:\n",
    "                corr = np.nan\n",
    "\n",
    "            self.pair_scores.append((core1, core2, crmsd, corr, len(merged)))\n",
    "\n",
    "    def _filter_pairs(self):\n",
    "        start = time.time()\n",
    "        self.filtered_pairs = [\n",
    "            (s1, s2) for s1, s2, rmsd, corr, n in self.pair_scores\n",
    "            if rmsd <= self.crmsd_thresh and (not np.isnan(corr) and corr >= self.pearson_thresh)\n",
    "        ]\n",
    "\n",
    "    def _augment(self):\n",
    "        start = time.time()\n",
    "        augmented_entries = []\n",
    "\n",
    "        for s1, s2 in tqdm(self.filtered_pairs, desc=\"4) Augmenting data\"):\n",
    "            df1 = self.series[s1]\n",
    "            df2 = self.series[s2]\n",
    "\n",
    "            tf1 = df1[[\"L_sub\", \"R_sub\", \"Delta_Y\"]].to_dict(\"records\")\n",
    "            tf2 = df2[[\"L_sub\", \"R_sub\", \"Delta_Y\"]].to_dict(\"records\")\n",
    "\n",
    "            df1_dict = defaultdict(list)\n",
    "            for _, row in df1.iterrows():\n",
    "                df1_dict[row[\"L_sub\"]].append(row.to_dict())\n",
    "\n",
    "            df2_dict = defaultdict(list)\n",
    "            for _, row in df2.iterrows():\n",
    "                df2_dict[row[\"L_sub\"]].append(row.to_dict())\n",
    "\n",
    "            for entry in tf1:\n",
    "                l_sub = entry[\"L_sub\"]\n",
    "                for base in df2_dict.get(l_sub, []):\n",
    "                    r_sub = entry[\"R_sub\"]\n",
    "                    delta = entry[\"Delta_Y\"]\n",
    "                    new_y = base[\"L_Y\"] + delta\n",
    "                    smirks_new = l_sub + \">>\" + r_sub\n",
    "                    augmented_entries.append({\n",
    "                        \"CORE\": s1,\n",
    "                        \"L_sub\": l_sub,\n",
    "                        \"R_sub\": r_sub,\n",
    "                        \"L_Y\": base[\"L_Y\"],\n",
    "                        \"R_Y\": new_y,\n",
    "                        \"Delta_Y\": delta,\n",
    "                        \"AUG\": True,\n",
    "                        \"L_SMILES\": base.get(\"L_SMILES\"),\n",
    "                        \"L_ID\": base.get(\"L_ID\"),\n",
    "                        \"L_sub_ID\": base.get(\"L_sub_ID\"),\n",
    "                        \"R_sub_ID\": base64.urlsafe_b64encode(r_sub.encode()).decode(),\n",
    "                        \"SMIRKS\": smirks_new,\n",
    "                        \"SMIRKS_ID\": base64.urlsafe_b64encode(smirks_new.encode()).decode(),\n",
    "                        \"CORE_ID\": base64.urlsafe_b64encode(s1.encode()).decode()\n",
    "                    })\n",
    "\n",
    "            for entry in tf2:\n",
    "                l_sub = entry[\"L_sub\"]\n",
    "                for base in df1_dict.get(l_sub, []):\n",
    "                    r_sub = entry[\"R_sub\"]\n",
    "                    delta = entry[\"Delta_Y\"]\n",
    "                    new_y = base[\"L_Y\"] + delta\n",
    "                    smirks_new = l_sub + \">>\" + r_sub\n",
    "                    augmented_entries.append({\n",
    "                        \"CORE\": s2,\n",
    "                        \"L_sub\": l_sub,\n",
    "                        \"R_sub\": r_sub,\n",
    "                        \"L_Y\": base[\"L_Y\"],\n",
    "                        \"R_Y\": new_y,\n",
    "                        \"Delta_Y\": delta,\n",
    "                        \"AUG\": True,\n",
    "                        \"L_SMILES\": base.get(\"L_SMILES\"),\n",
    "                        \"L_ID\": base.get(\"L_ID\"),\n",
    "                        \"L_sub_ID\": base.get(\"L_sub_ID\"),\n",
    "                        \"R_sub_ID\": base64.urlsafe_b64encode(r_sub.encode()).decode(),\n",
    "                        \"SMIRKS\": smirks_new,\n",
    "                        \"SMIRKS_ID\": base64.urlsafe_b64encode(smirks_new.encode()).decode(),\n",
    "                        \"CORE_ID\": base64.urlsafe_b64encode(s2.encode()).decode()\n",
    "                    })\n",
    "\n",
    "        self.augmented_data = pd.DataFrame(augmented_entries)\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self._extract_series()\n",
    "        self._compute_pairwise_scores()\n",
    "        self._filter_pairs()\n",
    "        self._augment()\n",
    "\n",
    "        original = self.df.copy()\n",
    "        original[\"AUG\"] = False\n",
    "        return pd.concat([original, self.augmented_data], ignore_index=True)\n",
    "    \n",
    "    def get_pair_scores_df(self):\n",
    "        \"\"\"\n",
    "        Return a DataFrame of scaffold pair scores (cRMSD, Pearson, common MMP count)\n",
    "        \"\"\"\n",
    "        return pd.DataFrame(\n",
    "            self.pair_scores,\n",
    "            columns=[\"Scaffold_1\", \"Scaffold_2\", \"cRMSD\", \"Pearson\", \"N_common\"]\n",
    "        )\n",
    "\n",
    "    def get_augmented_only(self):\n",
    "        \"\"\"\n",
    "        Return only the augmented (predicted) entries.\n",
    "        \"\"\"\n",
    "        return self.augmented_data.copy()\n",
    "    \n",
    "\n",
    "def analyze_scaffold_pair_scores(df):\n",
    "    summary = {\n",
    "        \"Total Pairs\": len(df),\n",
    "        \"Mean cRMSD\": df[\"cRMSD\"].mean(),\n",
    "        \"Median cRMSD\": df[\"cRMSD\"].median(),\n",
    "        \"Std cRMSD\": df[\"cRMSD\"].std(),\n",
    "        \"Mean Pearson\": df[\"Pearson\"].mean(),\n",
    "        \"Median Pearson\": df[\"Pearson\"].median(),\n",
    "        \"Std Pearson\": df[\"Pearson\"].std(),\n",
    "        \"Mean N_common\": df[\"N_common\"].mean(),\n",
    "        \"Median N_common\": df[\"N_common\"].median()\n",
    "    }\n",
    "\n",
    "    high_corr = df[\"Pearson\"] > 0.7\n",
    "    low_crmsd = df[\"cRMSD\"] < 0.5\n",
    "    enough_common = df[\"N_common\"] >= 5\n",
    "    strong_pairs = df[high_corr & low_crmsd & enough_common]\n",
    "\n",
    "    summary.update({\n",
    "        \"High Pearson (>0.7)\": high_corr.sum(),\n",
    "        \"Low cRMSD (<0.5)\": low_crmsd.sum(),\n",
    "        \"N_common ≥ 5\": enough_common.sum(),\n",
    "        \"Strong Pairs (all 3)\": len(strong_pairs)\n",
    "    })\n",
    "\n",
    "    top_corr = df.sort_values(\"Pearson\", ascending=False).head(5)\n",
    "    top_low_crmsd = df.sort_values(\"cRMSD\").head(5)\n",
    "    top_common = df.sort_values(\"N_common\", ascending=False).head(5)\n",
    "\n",
    "    return {\n",
    "        \"summary\": summary,\n",
    "        \"top_corr\": top_corr,\n",
    "        \"top_low_crmsd\": top_low_crmsd,\n",
    "        \"top_common\": top_common,\n",
    "        \"strong_pairs\": strong_pairs\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fast_apply_transformation(transformation, l_smiles, rxn_cache, core_cache, heavy_cache, core_smarts, failure_tracker=None):\n",
    "    if pd.isna(transformation) or pd.isna(l_smiles):\n",
    "        return None\n",
    "\n",
    "    # --- Cache reaction and Δheavy ---\n",
    "    if transformation not in rxn_cache:\n",
    "        try:\n",
    "            rxn = AllChem.ReactionFromSmarts(transformation)\n",
    "            left_smi, right_smi = transformation.split(\">>\")\n",
    "            left_mol = Chem.MolFromSmarts(left_smi)\n",
    "            right_mol = Chem.MolFromSmarts(right_smi)\n",
    "            delta_heavy = right_mol.GetNumHeavyAtoms() - left_mol.GetNumHeavyAtoms()\n",
    "            rxn_cache[transformation] = (rxn, delta_heavy)\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        rxn, delta_heavy = rxn_cache[transformation]\n",
    "\n",
    "    # --- Cache L_SMILES heavy atom count ---\n",
    "    if l_smiles not in heavy_cache:\n",
    "        mol_l = Chem.MolFromSmiles(l_smiles)\n",
    "        if mol_l is None:\n",
    "            return None\n",
    "        n_heavy_l = mol_l.GetNumHeavyAtoms()\n",
    "        heavy_cache[l_smiles] = (mol_l, n_heavy_l)\n",
    "    else:\n",
    "        mol_l, n_heavy_l = heavy_cache[l_smiles]\n",
    "\n",
    "    # --- Cache core mol ---\n",
    "    if core_smarts not in core_cache:\n",
    "        core_mol = Chem.MolFromSmarts(core_smarts)\n",
    "        if core_mol is None:\n",
    "            return None\n",
    "        core_cache[core_smarts] = core_mol\n",
    "    else:\n",
    "        core_mol = core_cache[core_smarts]\n",
    "\n",
    "    # --- Run reaction ---\n",
    "    try:\n",
    "        products = rxn.RunReactants((mol_l,))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if failure_tracker is not None:\n",
    "        failure_tracker[\"total\"] += 1\n",
    "        if not products:\n",
    "            failure_tracker[\"empty_prodsets\"] += 1\n",
    "\n",
    "    all_products = []\n",
    "    for prod_set in products:\n",
    "        if not prod_set and failure_tracker is not None:\n",
    "            failure_tracker[\"empty_prodsets\"] += 1\n",
    "        for prod in prod_set:\n",
    "            if prod is None:\n",
    "                continue\n",
    "            try:\n",
    "                if not prod.HasSubstructMatch(core_mol):\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            n_heavy_r = prod.GetNumHeavyAtoms()\n",
    "            if n_heavy_r - n_heavy_l != delta_heavy:\n",
    "                continue\n",
    "            all_products.append(Chem.MolToSmiles(prod, isomericSmiles=True))\n",
    "\n",
    "    return all_products if all_products else None\n",
    "\n",
    "def update_predicted_rows(df):\n",
    "    df = df.drop_duplicates()\n",
    "    mask = df[\"AUG\"] == True\n",
    "    indices = df[mask].index\n",
    "\n",
    "    rxn_cache = {}\n",
    "    heavy_cache = {}\n",
    "    core_cache = {}\n",
    "\n",
    "    new_rows = []\n",
    "    failure_tracker = {\"total\": 0, \"empty_prodsets\": 0}\n",
    "\n",
    "    for idx in tqdm(indices, desc=\"5) Updating predicted rows\"):\n",
    "        row = df.loc[idx]\n",
    "        l_smiles = row[\"L_SMILES\"]\n",
    "        smirks = row[\"SMIRKS\"]\n",
    "        core = row[\"CORE\"]\n",
    "\n",
    "        r_smiles_list = fast_apply_transformation(\n",
    "            smirks, l_smiles, rxn_cache, core_cache, heavy_cache, core,\n",
    "            failure_tracker=failure_tracker\n",
    "        )\n",
    "\n",
    "        if r_smiles_list:\n",
    "            for r_smiles in r_smiles_list:\n",
    "                mol = Chem.MolFromSmiles(r_smiles)\n",
    "                if mol:\n",
    "                    r_id = Chem.InchiToInchiKey(Chem.MolToInchi(mol))\n",
    "                    new_row = row.copy()\n",
    "                    new_row[\"R_SMILES\"] = r_smiles\n",
    "                    new_row[\"R_ID\"] = r_id\n",
    "                    new_rows.append(new_row)\n",
    "\n",
    "    df_non_aug = df[~mask]\n",
    "    df_aug_expanded = pd.DataFrame(new_rows)\n",
    "    df_final = pd.concat([df_non_aug, df_aug_expanded], ignore_index=True)\n",
    "\n",
    "    # Print failure rate\n",
    "    total = failure_tracker[\"total\"]\n",
    "    failed = failure_tracker[\"empty_prodsets\"]\n",
    "    if total > 0:\n",
    "        print(f\"⚠️  Empty product sets in {failed} / {total} ({100 * failed / total:.2f}%) of transformations\")\n",
    "\n",
    "    return df_final\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepare_and_plot_prediction_vs_experiment_complete_with_output(imputed_df, std_threshold=0.5):\n",
    "\n",
    "    print(\"6) Preparing output file\")\n",
    "\n",
    "    l_df = imputed_df[[\"L_SMILES\", \"L_Y\", \"AUG\"]]\n",
    "    r_df = imputed_df[[\"R_SMILES\", \"R_Y\", \"AUG\"]]\n",
    "    l_df.columns = [\"SMILES\", \"Y\", \"AUG\"]\n",
    "    r_df.columns = [\"SMILES\", \"Y\", \"AUG\"]\n",
    "    clean_df = pd.concat([l_df, r_df])\n",
    "\n",
    "\n",
    "    # Count total before\n",
    "    total_before = len(clean_df)\n",
    "\n",
    "    # Drop rows with missing or invalid SMILES\n",
    "    clean_df = clean_df.dropna(subset=[\"SMILES\"]).copy()\n",
    "    clean_df = clean_df[clean_df[\"SMILES\"].apply(lambda x: Chem.MolFromSmiles(x) is not None)]\n",
    "\n",
    "    # Count total after\n",
    "    total_after = len(clean_df)\n",
    "\n",
    "    # Print failure rate\n",
    "    fail_pct = 100 * (total_before - total_after) / total_before\n",
    "    print(f\"Invalid SMILES removed: {total_before - total_after} / {total_before} ({fail_pct:.2f}%)\")\n",
    "\n",
    "    tqdm.pandas(desc=\"7) Standardizing SMILES\")\n",
    "    clean_df[\"SMILES\"] = clean_df[\"SMILES\"].progress_apply(\n",
    "        lambda x: Chem.MolToSmiles(Chem.MolFromSmiles(x), isomericSmiles=True)\n",
    "    )\n",
    "\n",
    "    # Step 8) InChIKey generation\n",
    "    tqdm.pandas(desc=\"8) Generating InChIKeys\")\n",
    "    clean_df['InChIKey'] = clean_df[\"SMILES\"].progress_apply(smiles_to_inchikey)\n",
    "\n",
    "\n",
    "    # Insert InChIKey as first column\n",
    "    cols = ['InChIKey'] + [col for col in clean_df.columns if col != 'InChIKey']\n",
    "    clean_df = clean_df[cols]\n",
    "\n",
    "\n",
    "    clean_df_exp = clean_df[clean_df[\"AUG\"] != True].copy()\n",
    "    clean_df_pred = clean_df[clean_df[\"AUG\"] == True].copy()\n",
    "\n",
    "    # Normalize column names\n",
    "    clean_df_exp = clean_df_exp.rename(columns={\"R_SMILES\": \"SMILES\", \"R_Y\": \"Y\"})\n",
    "    clean_df_pred = clean_df_pred.rename(columns={\"R_SMILES\": \"SMILES\", \"R_Y\": \"Y\"})\n",
    "\n",
    "    # Compute median and std per SMILES in predicted\n",
    "    grouped_pred = clean_df_pred.groupby(\"InChIKey\")[\"Y\"].agg([\"median\", \"std\"]).reset_index()\n",
    "    grouped_pred.columns = [\"InChIKey\", \"Y\", \"STD\"]\n",
    "    grouped_pred[\"AUG\"] = True\n",
    "\n",
    "    # Re-add SMILES by mapping InChIKey → first SMILES in original pred dataframe\n",
    "    inchikey_to_smiles = clean_df_pred.dropna(subset=[\"SMILES\"]).drop_duplicates(\"InChIKey\").set_index(\"InChIKey\")[\"SMILES\"].to_dict()\n",
    "    grouped_pred[\"SMILES\"] = grouped_pred[\"InChIKey\"].map(inchikey_to_smiles)\n",
    "    grouped_pred = grouped_pred[[\"InChIKey\", \"SMILES\", \"Y\", \"STD\", \"AUG\"]]\n",
    "    grouped_pred = grouped_pred[grouped_pred[\"STD\"]<= std_threshold]\n",
    "\n",
    "    # Final prediction rows\n",
    "    exp_out = clean_df_exp[['InChIKey', \"SMILES\", \"Y\"]].copy()\n",
    "    exp_out[\"STD\"] = None\n",
    "    exp_out[\"AUG\"] = False\n",
    "    exp_out = exp_out[[\"InChIKey\", \"SMILES\", \"Y\", \"STD\", \"AUG\"]]\n",
    "\n",
    "    exp_out = exp_out.dropna(how='all')\n",
    "    grouped_pred = grouped_pred.dropna(how='all')\n",
    "\n",
    "    # Remove predicted entries with InChIKey already in experimental\n",
    "    known_keys = set(exp_out['InChIKey'])\n",
    "    grouped_pred = grouped_pred[~grouped_pred['InChIKey'].isin(known_keys)]\n",
    "\n",
    "\n",
    "    output_df = pd.concat(\n",
    "    [exp_out.drop_duplicates(\"InChIKey\"), grouped_pred.drop_duplicates(\"InChIKey\")],\n",
    "    ignore_index=True\n",
    "    )\n",
    "\n",
    "    output_df = output_df[~((output_df['AUG'] == True) & (output_df['InChIKey'].isin(output_df.loc[output_df['AUG'] == False, 'InChIKey'])))]\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "# Compute InChIKey from SMILES\n",
    "def smiles_to_inchikey(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        return inchi.MolToInchiKey(mol)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "def assign_set_from_inchikey(output_df, reference_df, smiles_col=\"SMILES\", inchikey_col=\"InChIKey\", set_col=\"SET\"):\n",
    "    # Compute InChIKey for each SMILES in output_df\n",
    "    output_df[inchikey_col] = output_df[smiles_col].apply(\n",
    "        lambda smi: Chem.inchi.MolToInchiKey(Chem.MolFromSmiles(smi)) if Chem.MolFromSmiles(smi) else None\n",
    "    )\n",
    "    \n",
    "    # Create lookup from reference_df\n",
    "    inchikey_map = dict(zip(reference_df[inchikey_col], reference_df[set_col]))\n",
    "    \n",
    "    # Map SET\n",
    "    output_df[set_col] = output_df[inchikey_col].map(inchikey_map)\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "\n",
    "def smiles_to_morgan(smiles, radius=2, n_bits=2048):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)\n",
    "    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits))\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "base_dirs = [\"../data/noaug\", \"../data/aug\", \"../data/test\", \"../data/frag\"]\n",
    "combinations_set = [\"AB\", \"AC\", \"BC\"]\n",
    "combinations_second = [\"STL\", \"MTL\"]\n",
    "\n",
    "# Create main dirs\n",
    "for base in base_dirs:\n",
    "    Path(base).mkdir(parents=True, exist_ok=True)\n",
    "    # Create subdirs\n",
    "\n",
    "    \n",
    "    for combo in combinations_set:\n",
    "        if base != \"../data/frag\":\n",
    "            for combo_2 in combinations_second:\n",
    "                Path(f\"{base}/{combo}/{combo_2}\").mkdir(parents=True, exist_ok=True)\n",
    "        else:\n",
    "            Path(f\"{base}/{combo}\").mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782344b",
   "metadata": {},
   "source": [
    "# 1) Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55890779",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_heavy = 15\n",
    "max_ratio = 0.3\n",
    "min_common = 4\n",
    "pearson_thresh = 0.3\n",
    "crmsd_thresh = 0.6\n",
    "std_threshold = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6be4e",
   "metadata": {},
   "source": [
    "# 2) Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e40d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/1343 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: oneADMET_LR-STL---pIC$_{50}$ TGFR1 (HUMAN).parquet\n",
      "Train set: ['A', 'B']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:39] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:46] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:14:46] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:171: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr = pearsonr(y1, y2)[0]\n",
      "3) Computing pairwise correlations: 100%|██████████| 9424311/9424311 [00:34<00:00, 270886.57it/s]\n",
      "4) Augmenting data: 100%|██████████| 61/61 [00:00<00:00, 142.69it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 6024/6024 [00:01<00:00, 5464.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 6024 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 131296 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 131296/131296 [00:15<00:00, 8455.19it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 131296/131296 [00:24<00:00, 5278.12it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['A', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:16:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 10499653/10499653 [00:38<00:00, 271600.02it/s]\n",
      "4) Augmenting data: 100%|██████████| 47/47 [00:00<00:00, 188.03it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 4608/4608 [00:00<00:00, 5692.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 4608 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 122408 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 122408/122408 [00:14<00:00, 8537.75it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 122408/122408 [00:23<00:00, 5292.69it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['B', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3) Computing pairwise correlations: 100%|██████████| 11274126/11274126 [00:42<00:00, 264401.79it/s]\n",
      "4) Augmenting data: 100%|██████████| 86/86 [00:00<00:00, 115.68it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 12182/12182 [00:01<00:00, 7138.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 12182 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 141122 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 141122/141122 [00:16<00:00, 8454.49it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 141122/141122 [00:26<00:00, 5293.61it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n",
      "Processing datasets:   0%|          | 1/1343 [06:06<136:43:46, 366.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: oneADMET_LR-STL---pK$_{i}$ CXCR3 (HUMAN).parquet\n",
      "Train set: ['A', 'B']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:20:29] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:20:29] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 332520/332520 [00:01<00:00, 289018.68it/s]\n",
      "4) Augmenting data: 100%|██████████| 18/18 [00:00<00:00, 459.47it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 664/664 [00:00<00:00, 1863.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 664 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 18520 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 18520/18520 [00:01<00:00, 9870.91it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 18520/18520 [00:03<00:00, 5987.97it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['A', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:20:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:20:42] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 334153/334153 [00:01<00:00, 279509.91it/s]\n",
      "4) Augmenting data: 100%|██████████| 34/34 [00:00<00:00, 351.55it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 1587/1587 [00:00<00:00, 2335.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 1587 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 20896 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 20896/20896 [00:02<00:00, 9378.51it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 20896/20896 [00:03<00:00, 5878.66it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['B', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3) Computing pairwise correlations: 100%|██████████| 346528/346528 [00:01<00:00, 280393.28it/s]\n",
      "4) Augmenting data: 100%|██████████| 43/43 [00:00<00:00, 404.74it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 1500/1500 [00:00<00:00, 1981.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 1500 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 23288 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 23288/23288 [00:02<00:00, 9454.89it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 23288/23288 [00:03<00:00, 5854.54it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n",
      "Processing datasets:   0%|          | 2/1343 [06:50<65:53:27, 176.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: oneADMET_LR-STL---pIC$_{50}$ AMPN (HUMAN).parquet\n",
      "Train set: ['A', 'B']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:12] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:12] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:12] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:12] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:13] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:171: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr = pearsonr(y1, y2)[0]\n",
      "3) Computing pairwise correlations: 100%|██████████| 621055/621055 [00:02<00:00, 297209.12it/s]\n",
      "4) Augmenting data: 100%|██████████| 14/14 [00:00<00:00, 283.46it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 768/768 [00:00<00:00, 3371.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 768 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 21372 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 21372/21372 [00:01<00:00, 14173.83it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 21372/21372 [00:02<00:00, 8271.80it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['A', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:26] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:171: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr = pearsonr(y1, y2)[0]\n",
      "3) Computing pairwise correlations: 100%|██████████| 608856/608856 [00:02<00:00, 293365.89it/s]\n",
      "4) Augmenting data: 100%|██████████| 1/1 [00:00<00:00, 543.51it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 36/36 [00:00<00:00, 5960.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 36 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 22796 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 22796/22796 [00:01<00:00, 15444.64it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 22796/22796 [00:02<00:00, 8506.60it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['B', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 408156/408156 [00:01<00:00, 298622.73it/s]\n",
      "4) Augmenting data: 100%|██████████| 11/11 [00:00<00:00, 332.05it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 786/786 [00:00<00:00, 6844.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 786 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 15310 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 15310/15310 [00:01<00:00, 14414.63it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 15310/15310 [00:01<00:00, 7887.79it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n",
      "Processing datasets:   0%|          | 3/1343 [07:26<41:53:59, 112.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: oneADMET_LR-STL---pIC$_{50}$ ANM6 (HUMAN).parquet\n",
      "Train set: ['A', 'B']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:45] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 28920/28920 [00:00<00:00, 300446.52it/s]\n",
      "4) Augmenting data: 0it [00:00, ?it/s]\n",
      "5) Updating predicted rows: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 4976 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 4976/4976 [00:00<00:00, 14184.56it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 4976/4976 [00:00<00:00, 8253.95it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['A', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:49] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 64261/64261 [00:00<00:00, 292511.64it/s]\n",
      "4) Augmenting data: 0it [00:00, ?it/s]\n",
      "5) Updating predicted rows: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 8360 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 8360/8360 [00:00<00:00, 13426.41it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 8360/8360 [00:01<00:00, 8130.92it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['B', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:21:54] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:21:54] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 77815/77815 [00:00<00:00, 312295.55it/s]\n",
      "4) Augmenting data: 0it [00:00, ?it/s]\n",
      "5) Updating predicted rows: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 6296 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 6296/6296 [00:00<00:00, 13006.79it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 6296/6296 [00:00<00:00, 7457.98it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n",
      "Processing datasets:   0%|          | 4/1343 [07:39<27:11:57, 73.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: oneADMET_LR-STL---pIC$_{50}$ MP2K1 (HUMAN).parquet\n",
      "Train set: ['A', 'B']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:19] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:20] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:20] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:23] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:23] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:24] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:22:25] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 4661931/4661931 [00:16<00:00, 279942.74it/s]\n",
      "4) Augmenting data: 100%|██████████| 94/94 [00:00<00:00, 557.22it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 3142/3142 [00:00<00:00, 6882.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 3142 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 77282 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 77282/77282 [00:08<00:00, 9615.60it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 77282/77282 [00:12<00:00, 5952.27it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['A', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n",
      "2) Canonical SMIRKS generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:33] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:35] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:36] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:37] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:37] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "[23:23:38] WARNING: not removing hydrogen atom with dummy atom neighbors\n",
      "3) Computing pairwise correlations: 100%|██████████| 4492503/4492503 [00:16<00:00, 274905.50it/s]\n",
      "4) Augmenting data: 100%|██████████| 60/60 [00:00<00:00, 251.16it/s]\n",
      "5) Updating predicted rows: 100%|██████████| 3230/3230 [00:00<00:00, 3951.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Empty product sets in 0 / 3230 (0.00%) of transformations\n",
      "6) Preparing output file\n",
      "Invalid SMILES removed: 0 / 83728 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7) Standardizing SMILES: 100%|██████████| 83728/83728 [00:08<00:00, 9541.50it/s]\n",
      "8) Generating InChIKeys: 100%|██████████| 83728/83728 [00:14<00:00, 5914.26it/s]\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2389703348.py:511: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  output_df = pd.concat(\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"STD\"] = None\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train[\"AUG\"] = False\n",
      "/var/folders/2b/_90d0zxj2w3gcjdjskhc3xhw0000gn/T/ipykernel_37845/2891387838.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test[\"AUG\"] = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: ['B', 'C']\n",
      "0) Fragments generation\n",
      "1) Indexing\n"
     ]
    }
   ],
   "source": [
    "iterated_datasets = [i for i in os.listdir('../data/aug/BC/') if i.endswith('.parquet')]\n",
    "\n",
    "for dataset in tqdm(os.listdir('../data/exp/STL/'), desc = \"Processing datasets\"):\n",
    "    print(\"Dataset:\", dataset)\n",
    "    if dataset not in iterated_datasets:\n",
    "        df = pd.read_parquet(f'../data/exp/STL/{dataset}')\n",
    "        for train_set in ([\"A\", \"B\"], [\"A\", \"C\"], [\"B\", \"C\"]): # pass it to parralel \n",
    "            print(\"Train set:\", train_set)\n",
    "\n",
    "            set_ID = \"\".join(train_set)\n",
    "            \n",
    "            df_train = df[df[\"SET\"].isin(train_set)]\n",
    "            df_test = df[~df[\"SET\"].isin(train_set)]\n",
    "\n",
    "            output_csv = f'../data/frag/{set_ID}/{dataset}'\n",
    "            \n",
    "            MMPGenerator(df_train, output_csv=output_csv, symmetric=True, max_heavy=max_heavy, max_ratio=max_ratio, verbose=True).run()\n",
    "            augmentor = MMPAugmentorFixed(pd.read_csv(output_csv, on_bad_lines=\"skip\") , min_common=min_common, pearson_thresh=pearson_thresh, crmsd_thresh=crmsd_thresh)\n",
    "            final_df2 = augmentor.run()\n",
    "            imputed_df = update_predicted_rows(final_df2)\n",
    "            clean_df = prepare_and_plot_prediction_vs_experiment_complete_with_output(imputed_df, std_threshold=std_threshold)\n",
    "            output_df = assign_set_from_inchikey(clean_df, df)\n",
    "\n",
    "\n",
    "            output_df.to_parquet(f'../data/aug/{set_ID}/STL/{dataset}', index=False)\n",
    "\n",
    "            df_train[\"STD\"] = None\n",
    "            df_test[\"STD\"] = None\n",
    "            df_train[\"AUG\"] = False\n",
    "            df_test[\"AUG\"] = False\n",
    "\n",
    "            df_train = df_train[['InChIKey', 'SMILES', 'Y', 'STD', 'AUG', 'SET']]\n",
    "            df_test = df_test[['InChIKey', 'SMILES', 'Y', 'STD', 'AUG', 'SET']]\n",
    "\n",
    "            df_train.to_parquet(f'../data/noaug/{set_ID}/STL/{dataset}', index=False)\n",
    "            df_test.to_parquet(f'../data/test/{set_ID}/STL/{dataset}', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5f422",
   "metadata": {},
   "source": [
    "# 3) Prepare the MTL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemprop_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
